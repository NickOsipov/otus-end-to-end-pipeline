{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <left> Benchmark Serialization </left> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "import onnxruntime\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from sklearn2pmml import PMMLPipeline\n",
    "from sklearn2pmml import sklearn2pmml\n",
    "from pypmml import Model\n",
    "\n",
    "from tabulate import tabulate\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—É—Ç–µ–π –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π\n",
    "models_dir = \"models\"\n",
    "models_path = os.path.join(\"..\", models_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_models_dir():\n",
    "    \"\"\"–°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –º–æ–¥–µ–ª–µ–π, –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç\"\"\"\n",
    "    os.makedirs(models_path, exist_ok=True)\n",
    "    print(f\"\\nüìÅ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –º–æ–¥–µ–ª–µ–π —Å–æ–∑–¥–∞–Ω–∞: {models_path}\")\n",
    "\n",
    "def generate_data(n_samples=10000, n_features=20):\n",
    "    \"\"\"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö\"\"\"\n",
    "    print(\"\\nüîß –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö...\")\n",
    "    X, y = make_classification(\n",
    "        n_samples=n_samples,\n",
    "        n_features=n_features,\n",
    "        n_informative=15,\n",
    "        n_redundant=5,\n",
    "        random_state=42\n",
    "    )\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    print(f\"‚úÖ –î–∞–Ω–Ω—ã–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã: {n_samples} —Å—ç–º–ø–ª–æ–≤, {n_features} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\")\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def create_pipeline():\n",
    "    \"\"\"–°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞\"\"\"\n",
    "    return Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('pca', PCA(n_components=4)),\n",
    "        ('clf', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "    ])\n",
    "\n",
    "def train_model(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\"\"\"\n",
    "    print(\"\\nüöÄ –û–±—É—á–µ–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞...\")\n",
    "    model = create_pipeline()\n",
    "    model.fit(X_train, y_train)\n",
    "    train_score = model.score(X_train, y_train)\n",
    "    test_score = model.score(X_test, y_test)\n",
    "    print(f\"‚úÖ –ü–∞–π–ø–ª–∞–π–Ω –æ–±—É—á–µ–Ω: Train accuracy = {train_score:.4f}, Test accuracy = {test_score:.4f}\")\n",
    "    return model\n",
    "\n",
    "def save_models(model, X_train, y_train):\n",
    "    \"\"\"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö\"\"\"\n",
    "    print(\"\\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞ –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö...\")\n",
    "    create_models_dir()\n",
    "    save_paths = {}\n",
    "    \n",
    "    # Pickle\n",
    "    pickle_path = os.path.join(models_path, 'model.pkl')\n",
    "    with open(pickle_path, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    save_paths['pickle'] = pickle_path\n",
    "\n",
    "    # Joblib\n",
    "    joblib_path = os.path.join(models_path, 'model.joblib')\n",
    "    joblib.dump(model, joblib_path)\n",
    "    save_paths['joblib'] = joblib_path\n",
    "\n",
    "    # ONNX\n",
    "    initial_type = [('float_input', FloatTensorType([None, X_train.shape[1]]))]\n",
    "    onnx_model = convert_sklearn(model, initial_types=initial_type)\n",
    "    onnx_path = os.path.join(models_path, 'model.onnx')\n",
    "    with open(onnx_path, \"wb\") as f:\n",
    "        f.write(onnx_model.SerializeToString())\n",
    "    save_paths['onnx'] = onnx_path\n",
    "\n",
    "    # PMML\n",
    "    pmml_pipeline = PMMLPipeline([(\"pipeline\", model)])\n",
    "    pmml_pipeline.fit(X_train, y_train)\n",
    "    pmml_path = os.path.join(models_path, 'model.pmml')\n",
    "    sklearn2pmml(pmml_pipeline, pmml_path)\n",
    "    save_paths['pmml'] = pmml_path\n",
    "\n",
    "    print(\"‚úÖ –ü–∞–π–ø–ª–∞–π–Ω—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤–æ –≤—Å–µ—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö\")\n",
    "    return save_paths\n",
    "\n",
    "def benchmark_models(save_paths, X_test):\n",
    "    \"\"\"–ò–∑–º–µ—Ä–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π\"\"\"\n",
    "    print(\"\\nüìä –ù–∞—á–∞–ª–æ –±–µ–Ω—á–º–∞—Ä–∫–∏–Ω–≥–∞...\")\n",
    "    results = []\n",
    "\n",
    "    for format_name, path in save_paths.items():\n",
    "        # –ò–∑–º–µ—Ä–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞\n",
    "        size_mb = os.path.getsize(path) / (1024 * 1024)\n",
    "        \n",
    "        # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ –∏–∑–º–µ—Ä–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞\n",
    "        if format_name == 'pickle':\n",
    "            with open(path, 'rb') as f:\n",
    "                model = pickle.load(f)\n",
    "            start_time = time.time()\n",
    "            predictions = model.predict(X_test)\n",
    "            inference_time = (time.time() - start_time) * 1000\n",
    "\n",
    "        elif format_name == 'joblib':\n",
    "            model = joblib.load(path)\n",
    "            start_time = time.time()\n",
    "            predictions = model.predict(X_test)\n",
    "            inference_time = (time.time() - start_time) * 1000\n",
    "\n",
    "        elif format_name == 'onnx':\n",
    "            session = onnxruntime.InferenceSession(path)\n",
    "            input_name = session.get_inputs()[0].name\n",
    "            start_time = time.time()\n",
    "            predictions = session.run(None, {input_name: X_test.astype(np.float32)})[0]\n",
    "            inference_time = (time.time() - start_time) * 1000\n",
    "\n",
    "        elif format_name == 'pmml':\n",
    "            model = Model.load(path)\n",
    "            start_time = time.time()\n",
    "            predictions = model.predict(X_test)\n",
    "            inference_time = (time.time() - start_time) * 1000\n",
    "        \n",
    "        results.append([\n",
    "            format_name,\n",
    "            f\"{size_mb:.2f}\",\n",
    "            f\"{inference_time:.2f}\"\n",
    "        ])\n",
    "\n",
    "    # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ –≤–∏–¥–µ —Ç–∞–±–ª–∏—Ü—ã\n",
    "    headers = [\"–§–æ—Ä–º–∞—Ç\", \"–†–∞–∑–º–µ—Ä (MB)\", \"–í—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ (ms)\"]\n",
    "    print(\"\\nüìà –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±–µ–Ω—á–º–∞—Ä–∫–∞:\")\n",
    "    print(tabulate(results, headers=headers, tablefmt=\"grid\"))\n",
    "    return results\n",
    "\n",
    "def cleanup_files(save_paths):\n",
    "    \"\"\"–û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤\"\"\"\n",
    "    for path in save_paths.values():\n",
    "        if os.path.exists(path):\n",
    "            os.remove(path)\n",
    "    print(\"\\nüßπ –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã —É–¥–∞–ª–µ–Ω—ã\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö...\n",
      "‚úÖ –î–∞–Ω–Ω—ã–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã: 10000 —Å—ç–º–ø–ª–æ–≤, 20 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
      "\n",
      "üöÄ –û–±—É—á–µ–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞...\n",
      "‚úÖ –ü–∞–π–ø–ª–∞–π–Ω –æ–±—É—á–µ–Ω: Train accuracy = 0.9999, Test accuracy = 0.7600\n",
      "\n",
      "üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞ –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö...\n",
      "\n",
      "üìÅ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –º–æ–¥–µ–ª–µ–π —Å–æ–∑–¥–∞–Ω–∞: ../models\n",
      "‚úÖ –ü–∞–π–ø–ª–∞–π–Ω—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤–æ –≤—Å–µ—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö\n",
      "\n",
      "üìä –ù–∞—á–∞–ª–æ –±–µ–Ω—á–º–∞—Ä–∫–∏–Ω–≥–∞...\n",
      "\n",
      "üìà –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±–µ–Ω—á–º–∞—Ä–∫–∞:\n",
      "+----------+---------------+------------------------+\n",
      "| –§–æ—Ä–º–∞—Ç   |   –†–∞–∑–º–µ—Ä (MB) |   –í—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ (ms) |\n",
      "+==========+===============+========================+\n",
      "| pickle   |         18.61 |                  30.52 |\n",
      "+----------+---------------+------------------------+\n",
      "| joblib   |         18.62 |                  32.22 |\n",
      "+----------+---------------+------------------------+\n",
      "| onnx     |          9.03 |                  11.72 |\n",
      "+----------+---------------+------------------------+\n",
      "| pmml     |         48.94 |                1112.12 |\n",
      "+----------+---------------+------------------------+\n",
      "\n",
      "üßπ –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã —É–¥–∞–ª–µ–Ω—ã\n"
     ]
    }
   ],
   "source": [
    "# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö\n",
    "X_train, X_test, y_train, y_test = generate_data()\n",
    "\n",
    "# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "model = train_model(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö\n",
    "save_paths = save_models(model, X_train, y_train)\n",
    "\n",
    "# –ü—Ä–æ–≤–µ–¥–µ–Ω–∏–µ –±–µ–Ω—á–º–∞—Ä–∫–∞\n",
    "results = benchmark_models(save_paths, X_test)\n",
    "\n",
    "# –û—á–∏—Å—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)\n",
    "cleanup_files(save_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
